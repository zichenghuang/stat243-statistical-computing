Zicheng Huang
PS6 Question1

1. 
The goal of the simulation study is to investigate the finite sample properties of the likelihood ratio test in determining the mixture distribution, more specifically, choosing between a k0-component normal mixture versus a k1-component normal mixture. 
The metrics being considered in assessing the method are the significance level and the statistical power of the likelihood ratio test statistic. 

2. 
In designing their simulation study, the authors first need to choose the value of k0 and k1 for the two competing distributions, together with the values of the mixing proportion and the distance between the components of the competing distribution. They also need to determine the different sample sizes under investigation and how many samples should be generated to make the analysis. 
The size of the samples and the level of separation of the components of the competing distribution are some key aspects of the data generating mechanism that likely affect the statistical power. 
The data generating mechanism considered in this paper does not consider the scenario where the components of the competing distributions have difference variance. This might be something useful to consider.

3.
Their tables in general do a good job of presenting the simulation results by showing the comparison of significance level and statistical power under different sample sizes, mixing proportions, and magnitudes of separation between components. In some cases, a static graphical representation of the results may also be a good choice. However, it might be too complicated to construct a good static graphic when the number of changing variables gets larger. In this case, we might need to implement a dynamic graphical representation of the simulation results. 

4.
The values in tables 2 and 4 represents the simulated power, which is the percentage of the 1000 repetitions of the simulated samples from the alternative hypothesis distribution where the null hypothesis is rejected based on the corresponding test statistics of the simulated samples. In general, the more separated the components of the mixture distribution where the simulated samples are generated from, the easier to reject the null hypothesis where the number of components in the mixture distribution is always smaller. This is in general consistent with the results shown in the tables 2 and 4. Table 2 suggests that the statistical power is low for sample size less than 200 where the components of the mixture distribution is not well separated. Under the condition of components being well separated, at least a sample size of 100 is needed to be able to observe a reasonable statistical power. According to the table, we cannot see a relationship between power and the mixing proportion. By observing that the unadjusted test tends to reject the null hypothesis more often does the adjusted test, it is reasonable in that the convergence of the unadjusted test is not as accurate. Table 4 presents similar results, with two sets of mixing proportions, that larger separation between components and larger sample sizes are correlated with a larger statistical power.


5.
The authors decide to use 1000 simulations because the more simulation the better the approximation of the distribution and better accuracy in terms of the rejection region. The number of repetition will affect the simulated significance level summarized in Table 1 and 3. Thus, authors may decide to use 1000 simulations in order to get a better rate of convergence of the test statistic toward the asymptotic distribution so as to have a better representation of the underline population. The simulation size of 10 is too small to give enough information needed for the distribution and not representative of the population. If more than 1000 simulations can give better results and convergence, then it might be useful to take more than 1000 simulations. However, if the implementation of more simulations does not lead to a better result, instead, only similar level of results, then 1000 simulations may be enough. Moreover, it is often the time being too costly to run too large number of repetitions. 